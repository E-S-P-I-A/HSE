{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfsfNX04LM4kZvUYdJOcWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/E-S-P-I-A/HSE/blob/main/ML_HW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import csv\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_brand_from_url(url):\n",
        "    \"\"\"Простая функция для извлечения предполагаемого бренда из URL\"\"\"\n",
        "    common_brands = ['apple', 'google', 'microsoft', 'paypal', 'amazon',\n",
        "                    'facebook', 'netflix', 'instagram', 'whatsapp', 'discord',\n",
        "                    'office365', 'crypto', 'wallet', 'bet365']\n",
        "    url_lower = url.lower()\n",
        "    for brand in common_brands:\n",
        "        if brand in url_lower:\n",
        "            return brand.capitalize()\n",
        "    return \"Unknown\"\n",
        "\n",
        "# Настройки\n",
        "FEED_URL = 'https://openphish.com/feed.txt'\n",
        "INTERVAL = 5 * 60          # 5 минут\n",
        "DURATION = 60 * 60         # 1 час\n",
        "OUTPUT_CSV = 'openphish_data.csv'\n",
        "\n",
        "# Инициализация\n",
        "seen = set()\n",
        "data = []\n",
        "start_time = datetime.now()\n",
        "\n",
        "print(f'Начинаем парсинг в {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "\n",
        "# Основной цикл сбора данных\n",
        "end_time = time.time() + DURATION\n",
        "iteration = 1\n",
        "\n",
        "while time.time() < end_time:\n",
        "    try:\n",
        "        print(f'Итерация {iteration}: получаем данные...')\n",
        "        response = requests.get(FEED_URL, timeout=30)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            urls = [url.strip() for url in response.text.strip().split('\\n') if url.strip()]\n",
        "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "            new_urls = 0\n",
        "            for url in urls:\n",
        "                if url and url not in seen:\n",
        "                    seen.add(url)\n",
        "                    brand = extract_brand_from_url(url)\n",
        "                    data.append((url, brand, timestamp))\n",
        "                    new_urls += 1\n",
        "\n",
        "            print(f'Итерация {iteration}: всего URL в фиде: {len(urls)}, новых: {new_urls}, уникальных накоплено: {len(seen)}')\n",
        "        else:\n",
        "            print(f'Ошибка HTTP: {response.status_code}')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Ошибка при получении данных: {e}')\n",
        "\n",
        "    # Ждём следующую итерацию (кроме последней)\n",
        "    if time.time() + INTERVAL < end_time:\n",
        "        print(f'Ждём {INTERVAL} секунд до следующей проверки...')\n",
        "        time.sleep(INTERVAL)\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "finish_time = datetime.now()\n",
        "print(f'Парсинг завершён в {finish_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "\n",
        "# Сохранение результатов\n",
        "with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['URL', 'Brand', 'Timestamp'])\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(f'Данные сохранены в файл: {OUTPUT_CSV}')\n",
        "\n",
        "# Итоговые метрики\n",
        "print('\\n=== РЕЗУЛЬТАТЫ ===')\n",
        "print(f'Start: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "print(f'Finish: {finish_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "print(f'Unique URLs: {len(seen)}')\n",
        "\n",
        "if data:\n",
        "    brands = [brand for _, brand, _ in data]\n",
        "    top3 = Counter(brands).most_common(3)\n",
        "    print('Top-3 brands:')\n",
        "    for brand, count in top3:\n",
        "        print(f'{brand} — {count}')\n",
        "else:\n",
        "    print('Данные не получены. Проверьте доступность OpenPhish.com')\n",
        "\n",
        "print(f'\\nВсего записей в данных: {len(data)}')\n"
      ],
      "metadata": {
        "id": "uvKIPz3QqwLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}